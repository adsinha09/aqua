<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Automating Experimental Optics with Sample Efficient Machine Learning Methods</title>
    <link rel="stylesheet" href="assets/css/style.css">
</head>
<body>
    <header>
        <h1>Automating Experimental Optics with Sample Efficient Machine Learning Methods</h1>
        <p><strong>Paper Link:</strong> <a href="https://arxiv.org/abs/2503.14260">arXiv:2503.14260</a></p>
        <p><strong>For more information:</strong> <a href="https://github.com/arindam5aha/aqua">GitHub Repository</a></p>
    </header>

    <section>
        <h2>Visualising the Observation Space</h2>
        <h2>Visualising Different Hermite-Gauss Modes</h2>
        <p>These outputs are simulated.</p>
        <img src="Final_Plots_files/Final_Plots_5_0.png" alt="Hermite-Gauss Modes">

        <h2>Calculating Finesse from Full FSR Trace</h2>
        <p>Analysing both transmission and reflection traces:</p>
        <ul>
            <li>Top two peak positions: [1.41426484, 1.42037134]</li>
            <li>FWHM of the top two peaks: [4.375, 3.50930248]</li>
            <li>Difference between top two peak positions: 504</li>
            <li>Ratio of difference to FWHM: [115.2, 143.618284]</li>
        </ul>
        <p>Finesses used for paper: 129.40914200074948</p>

        <h2>Control Specs</h2>
        <p>Bounds for the optimization and control:</p>
        <p>The values represent the thread counts moved by the actuators. For more info visit: <a href="https://www.thorlabs.com/navigation.cfm?guide_id=83">Thorlabs</a></p>
        <ul>
            <li>Lens_1: (-100000, 100000)</li>
            <li>Lens_2: (-100000, 100000)</li>
            <li>Mirror_1x: (-5000, 5000)</li>
            <li>Mirror_1y: (-5000, 5000)</li>
            <li>Mirror_2x: (-5000, 5000)</li>
            <li>Mirror_2y: (-5000, 5000)</li>
        </ul>

        <h2>Reward Function Used in Experiment: <em>&eta;</em></h2>
        <p>This is the sole reward function used in the experiment for both SANN and AQUA.</p>
        <pre><code>def noisy_eta(obs, target_region=(400, 550)):
    target_integral = np.trapz(obs[target_region[0]:target_region[1]])
    complete_integral = np.trapz(obs)
    eta = target_integral / complete_integral
    return eta
        </code></pre>

        <h2>Corrected Reward Function: <em>&eta;'</em></h2>
        <p>Used to post-process all collected data and use for comparison.</p>
        <pre><code>def corrected_eta(obs, distance=5, prominence=5e-3, target_region=(400, 550)):
    obs = obs - np.median(obs)
    peaks, _ = find_peaks(obs, distance=distance, prominence=prominence)
    target_pk_height = max(obs[target_region[0]: target_region[1]])
    sum_pk_height = np.sum(obs[peaks])
    eta_prime = target_pk_height / sum_pk_height
    return eta_prime
        </code></pre>

        <h2>Results and Discussion</h2>
        <h3>Manual Alignment</h3>
        <img src="Final_Plots_files/Final_Plots_18_0.png" alt="Manual Alignment 1">
        <img src="Final_Plots_files/Final_Plots_19_0.png" alt="Manual Alignment 2">
        <ul>
            <li>MAX HUMAN MME: 0.9565508021390374</li>
            <li>MEAN HUMAN MME: 0.9319114506522006</li>
            <li>Std. Dev: 1.6788265680236416 %</li>
        </ul>

        <h3>SANN Optimisation on Experiment</h3>
        <img src="Final_Plots_files/Final_Plots_23_0.png" alt="SANN Optimisation">
        <p>Visualising best SANN results.</p>
        <img src="Final_Plots_files/Final_Plots_25_0.png" alt="SANN Results">

        <h3>Analyse AQUA Performance on Experiment</h3>
        <p>Loading run with resets.</p>
        <p>Loading No Reset Run.</p>
        <img src="Final_Plots_files/Final_Plots_31_0.png" alt="AQUA Performance">
        <ul>
            <li>Avg time per step: 5.435340497249661</li>
        </ul>
        <img src="Final_Plots_files/Final_Plots_33_0.png" alt="AQUA Performance Results">
        <ul>
            <li>MAX HUMAN MME: 95.66 %</li>
            <li>MEAN HUMAN MME: 93.19 %</li>
        </ul>

        <h2>Supplementary Information</h2>
        <h3>Linear Relation Between <em>&eta;</em> and <em>&eta;'</em></h3>
        <p>Each colored scatter plot represents an individual SANN run. The runs occurred on different days and as can be seen from the plot below, each run gives a slightly different slope suggesting change in conditions. Deviations seen are caused by noise. The detector offset causes the x-axis to have an offset, meaning <em>&eta;</em> does not reach 0.</p>
        <ul>
            <li>Slope: 1.78561321556722</li>
            <li>Intercept: -0.11827958713759489</li>
        </ul>
        <img src="Final_Plots_files/Final_Plots_36_1.png" alt="Linear Relation Plot">

        <h3>Thermal Drift</h3>
        <p>Fluctuations in target peak heights and its position.</p>
        <ul>
            <li>Best Cost Height: 1.7208110246574506</li>
            <li>Best Cost: 0.6379340335853348</li>
            <li>Transmittance: 1.7256962227402255</li>
        </ul>
        <img src="Final_Plots_files/Final_Plots_38_1.png" alt="Thermal Drift">

        <h3>Actuator Drifts</h3>
        <img src="Final_Plots_files/Final_Plots_40_0.png" alt="Actuator Drifts">

        <h3>Scatter Plots of the Parameter Space</h3>
        <img src="Final_Plots_files/Final_Plots_43_0.png" alt="Parameter Space Scatter Plots">

        <h2>AQUA: Model Specs</h2>
        <ul>
            <li>Observation size: 1024, raw data as shown above without offset corrections is used (continuous)</li>
            <li>Action size: 6, uses the full bounds as mentioned previously (continuous)</li>
        </ul>
        <h3>Models config:</h3>
        <ul>
            <li>Compatible with PyTorch version: 2.1.2</li>
            <li>CUDA version: 12.1</li>
            <li><a href="https://pytorch.org/">PyTorch</a></li>
            <li>hidden_size: {'encoder': 64, 'prediction': 64, 'policy': 512}</li>
            <li>num_hidden_layers: 2</li>
            <li>latent_size: 32</li>
            <li>activation: leakyRelu</li>
            <li>input_sizes: {'encoder': '1024 + (6)', 'prediction': '1024 + (6)', 'policy': '32 + (6)'}</li>
            <li>optimiser: Adam</li>
            <li>lr: 0.0001</li>
            <li>batch_size: {'encoder': 50, 'prediction': 50, 'policy': 200}</li>
            <li>clip_grad_norm: 1.0</li>
            <li>dropout: 0.2</li>
            <li>weights_initializer: kaiming_uniform</li>
        </ul>
        <p>Total no. of trainable parameters in the models: 558416</p>
        <p>(The latest version has 10x less parameters and much improved generalisation and training times)</p>

        <h2>AQUA: Pre-training</h2>
        <h2>AQUA: Reset Conditions</h2>
        <p>All resets shown in the paper apply a parameter chosen randomly from the entire given bounds. As seen in AQUA's online learning plot, these mostly return <em>&eta;'</em>=0. Below we visualise the associated observations and the parameters.</p>
        <img src="Final_Plots_files/Final_Plots_49_0.png" alt="AQUA Reset Conditions 1">
        <img src="Final_Plots_files/Final_Plots_49_1.png" alt="AQUA Reset Conditions 2">

        <h2>AQUA: Realign Without Retraining</h2>
        <img src="Final_Plots_files/Final_Plots_51_0.png" alt="AQUA Realign">

        <h2>AQUA: Visualising Top 5% Rewarded Observations</h2>
        <img src="Final_Plots_files/Final_Plots_53_0.png" alt="Top 5% Rewarded Observations">

        <h2>Cross Entropy Method (CEM) Sampling on Experiment</h2>
        <p>CEM is a pseudo-random importance sampling method. <a href="https://doi.org/10.1023/A:1010091220143">DOI: 10.1023/A:1010091220143</a></p>
        <img src="Final_Plots_files/Final_Plots_55_0.png" alt="CEM Sampling 1">
        <img src="Final_Plots_files/Final_Plots_56_0.png" alt="CEM Sampling 2">
        <p>As can be seen here, the reward landscape is different, given different configurations of the optics.</p>
        <img src="Final_Plots_files/Final_Plots_57_1.png" alt="CEM Reward Landscape">

        <h2>Compare AQUA with Standard Model-Free RL (Stable Baselines) in Cavity Simulation</h2>
        <p>It is to be noted that the simulations are free of all kinds of drifts and one can expect to get similar rewards for repeat measurements. Thanks to Viktoria-S. Schmiesing for help with setting up SB3 and its reward function and Aaron Tranter for the simulation. For more information on the simulation environment visit: <a href="https://www.gwoptics.org/pykat/">GW Optics</a> <a href="https://stable-baselines.readthedocs.io/en/master/">Stable Baselines</a> <a href="https://www.gymlibrary.dev/">OpenAI Gym</a></p>
        <img src="Final_Plots_files/Final_Plots_62_0.png" alt="AQUA vs Standard Model-Free RL">
        <p>Reward Functions used in simulation, with additional penalties to account for the multi-step architecture of standard model-free RL.</p>
    </section>

    <footer>
        <p>&copy; 2023 Automating Experimental Optics Project</p>
    </footer>

    <script src="assets/js/main.js"></script>
</body>
</html>